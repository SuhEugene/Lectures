# Способы сортировки последовательностей

**Сортировка** - перемещение элементов последовательности в порядке возрастания (неубывания) или убывания (невозрастания).

## Введение
### Области применения задачи сортировки

1. Задача группировки.
2. Поиск общих элементов в двух или более последовательностях.
3. Задача поиска.

### Постановка задачи

Пусть необходимо упорядочить $N$ записей: $R_1, R_2, ..., R_n$.  
Пусть каждая запись $R_i$ имеет ключ $k_i$, который и управляет процессом сортировки (в дальнейшем будем сортировать только ключи).

Введём на множестве ключей отношение порядка "меньше" такое, что для всех $a,b,c$ выполняются два условия:
1. Существует одно и только одно утверждение: $a < b$, $a > b$, $a = b$.
2. $a < b$ и $b < c$ $\Rightarrow$ $a < c$.

Любое множество с данным отношением подлежит сортировке в выбранном нами смысле. То есть записи упорядочиваются: $R_{i_1}, R_{i_2}, ..., R_{i_n}$, где $k_{i_1} \leq k_{i_2} \leq ... \leq k_{i_n}$.


## Базовые методы сортировки

Среди методов сортировки массивов выделяют три базовых:

- Метод прямого включения
- Метод прямого выбора
- Метод прямого обмена

### Метод прямого выбора

Среди всех элементов ищется минимальный и меняется местами с первым. Далее минимальный ищется среди оставшихся и меняется местами со вторым.
И так далее, пока массив не будет отсортирован.

Сложность метода на любом массиве будет $O(n^2)$, так как в методе два вложенных цикла: первый проходит $n-1$ итерацию, внутренний - $n-1, n-2, ...$ итераций.

Алгоритм простой и его реализация тоже будет проста:

```cpp
void selection (int* arr, int n) {
	for (int i = 0; i < n-1; i++) {
		int min = arr[i], min_index = i;
		for (int j = i+1; j < n; j++)
			if (arr[j] < min)
				min = arr[j],
				min_index = j;
		m[index] = m[i];
		m[i] = min;
	}
}
```

### Метод прямого включения (вставки)

$i$-й элемент вставляется среди предыдущих на подходящее для него место. Эта процедура проводится для всех элементов массива, начиная со второго и до последнего.

В худшем случае как и в среднем сложность - $O(n^2)$. Однако в лучшем случае (уже отсортированный массив) - $O(n)$, так как тело цикла `while` не будет выполняться ни разу.

```cpp
void insertion (int* arr, int n) {
	for (int i = 1; i < n; i++) {
		int el = arr[i], index = i;
		while (index != 0 && el < arr[index - 1])
			arr[index] = arr[index - 1], index--;
		arr[index] = el;
	}
}
```

### Метод прямого обмена

Также известен как метод пузырька.

1. Последний элемент массива сравнивается с предпоследним и если последний меньше - меняются местами.
2. Предпоследний элемент сравнивает с третьим с конца и снова упорядочиваются.
3. Так далее до начала массива. В результате на первом месте окажется минимальный элемент.
4. Процедура повторяется, но движемся до второго, третьего элемента и т.д.

Два вложенных цикла `for` дают сложность на любом входном массив $O(n^2)$.

Среди трёх базовых методов этот - самый медленный.

Алгоритм называется методом пузырька, так как если представить массив вертикальным, то элементы, имеющие меньшие значения на каждом проходе как лёгкие пузырьки в воде поднимаются вверх.

```cpp
void bubble(int *arr, int n) {
	for (int i = 0; i < n - 1; i++) {
		for (int j = n - 1; j > i; j--)
			if (arr[j] < arr[j - 1]) swap(arr[j], arr[j - 1]);
	}
}
```

## Улучшенные методы сортировки

### Шейкерная сортировка

Данный метод является улучшением пузырьковой сортировки.

Улучшения:

1. Запоминать были или нет перестановки в процессе некоторого прохода. Если нет, сортировку можно завершить.
2. Запоминать не только сам факт перестановки, но и место последнего обмена. Ясно, что после этого места массив уже отсортирован.
3. Проводить сортировку последовательно в двух направлениях по массиву. Сначала от конца к началу, а затем от начала к концу.

В лучшем случае на уже отсортированном массиве сложность будет $O(n)$, так как будет выполнен один раз первый цикл `for`, после чего `left` станет равен `right + 1`.

Однако в худшем случае (массив отсортирован в обратном порядке) сложность всё равно $O(n^2)$.

```cpp
void shaker(int *arr, int n) {
    int left = 1, right = n - 1, k = right;
    do {
        for (int j = right; j >= left; j--)
            if (arr[j] < arr[j - 1]) {
                swap(arr[j], arr[j - 1]);
                k = j;
            }
        left = k + 1;
  
        for (int j = left; j <= right; j++)
            if (arr[j] > arr[j - 1]) {
                swap(arr[j], arr[j - 1]);
                k = j;
            }
        right = k - 1;
    } while (left < right);
}
```

### Сортировка Шелла

Сортировка даёт выигрыш по сравнению с классическими методами, потому что на каждом шаге сортируется минимум элементов, либо элементы уже отсортированы.

В классической сортировке Шелла расстояние между элементами меняются как кратные чётные числа. На самом деле это не лучший вариант.

До сих пор окончательно неизвестно при каких расстояниях скорость - самая быстрая. Но точно известно, что они не должны быть множителями друг друга.

"Хороший" результат дают серии `1`, `4`, `13`, `40`, `121` или `1`, `3`, `7`, `15`, `31`, ... При этом сложность метода при хорошем распределении серии пропорционально $O(n^{1.2})$.

- Отдельно группируются и сортируются элементы стоящие друг от друга на расстоянии $n/2$. Затем на расстоянии $n/4$ и так далее, пока не дойдём до обычной одинарной сортировки.
- На каждом проходе сортировка программируется как сортировка вставками, поэтому если какая-то последовательность уже отсортирована, происходит переход к следующей.

Сортировка массива:

- 10, 4, 55, 66, 4, 123, 12, 666
- <span style="color:red">4</span>, <span style="color:aqua">4</span>, <span style="color:orange">12</span>, <span style="color:lime">66</span>, <span style="color:red">10</span>, <span style="color:aqua">123</span>, <span style="color:orange">55</span>, <span style="color:lime">666</span>
- <span style="color:red">4</span>, <span style="color:lime">4</span>, <span style="color:red">10</span>, <span style="color:lime">66</span>, <span style="color:red">12</span>, <span style="color:lime">123</span>, <span style="color:red">55</span>, <span style="color:lime">666</span>
- 4, 4, 10, 12, 55, 66, 123, 666

```cpp
void shell(int *arr, int n) {
	int step = n / 2;
	while (step > 0) {
		for (int i = 0; i < (n - step); i++) {
			int j = i;
			while (j >= 0 && m[j] > m[j + step]) {
				swap(m[j], m[j + step]);
				j -= step;
			}
		}
		step /= 2;
	}
}
```

### Пирамидальная сортировка

- Одномерный массив представляется в виде бинарного дерева. Левый потомок - элемент 1, правый - 2.
- Все узлы дерева выстраиваются в таком порядке, что никакой родитель не меньше своих прямых потомков.
- В результате такой процедуры в корне дерева (0й элемент массива) появляется наибольший элемент. Поменяем его местами с последним.
- Все элементы дерева находятся на своих местах за исключением нулевого элемента. Его нужно "протолкнуть" по дереву до требуемого места.
- После этого в корне дерева вновь оказывается максимальный элемент из оставшихся. Поменяем его местами с предпоследним.
- Повторяем алгоритм до тех пор пока первый элемент не сдвинуть.

```
Массив: [10 4 66 66 4 123 12 666]
Дерево:
         10
     4        55
   66  4   123   12
666
```

Выстраивание дерева в "хорошем" виде требует одноразового прохода по всем элементам: сложность подготовки - $O(n)$. В дальнейшем каждый элемент проталкиваем по дереву, затрачивая на это не более $log_2(n)$ и сложность $O(nlog_2(n))$.
 
Итоговая сложность: $O(n \times log_2(n))$ всегда.

```cpp
void push_down(int *arr, int root, int bottom) {
	bool done = false;
	int max_child;
	while ((root*2 + 1) <= bottom && !done) {
		if ((root*2 + 1) == bottom)
			max_child = root*2 + 1;
		else
			if (arr[root*2 + 1] > m[root*2 + 2])
				max_child = root*2 + 1;
			else
				max_child = root*2 + 2;

		if (arr[root] < arr[max_child]) {
			swap(arr[root], arr[max_child]);
			root = max_child;
		} else done = true;
}

void heap_sort(int *arr, int n) {
	for (int i = n/2 - 1; i >= 0; i--)
		pushDown(arr, i, n - 1);

	for (int i = n - 1; i >= 0; i--) {
		swap(arr[0], arr[i])
		pushDown(arr, 0, i - 1);
	}
}
```

### Быстрая сортировка

В массиве выбирается так называемый опорный элемент, стоящий в его центре.

После этого все элементы массива переставляются таким образом, что слева оказываются элементы, а справа - больше, либо равные.

Далее, данное правило применяется к левой и правой частям массива.

Обмен элементами производится следующим образом:
- Слева ищется элемент не меньше опорного
- Справа - не больший
- Меняются местами

И так далее


Если ключевой элемент выбирается таким образом, что все элементы массива делятся им по значениям ровно пополам, то левая и правая части относительно ключа будут одинаковы и количество таких делений.

При этом на каждом проходе пробегаем по всем элементам. Сложность: $O(n* \log{n})$.

Но в худшем случае, если ключом оказывается минимальный или максимальный элемент, то только он окажется на своём месте, а остальные элементы - либо справа, либо слева от него. Сложность: $O(n^2)$.

```cpp
void sort (int *arr, int left, int right) {
	int i = left, j = right, key = arr[(left + right) / 2];
	do {
		while (arr[i] < key) i++;
		while (arr[j] > key) j--;
		if (i <= j) {
			swap(arr[i], arr[j]);
			i++;
			j--;
		}
	} while (i <= j);
	if (i < right) sort(arr, i, right);
	if (j > left) sort(arr, left, j);
}

void quickSort(int *arr, int n) {
	sort(arr, 0, n - 1);
}
```

### Карманная сортировка

Это единственная сортировка, которая может упорядочить элементы за время $O(n)$, но для этого множество всех возможных значений ключа должно быть ограничено и мы это ограничение должны знать.

Для сортировки заводится массив "карманов". Каждый элемент массива (карман) - указатель на список, в котором расположены объекты с ключом, совпадающим с индексом "кармана".


## Внешняя сортировка

Файлы устроены таким образом, что в каждый момент времени доступна только одна компонента файла. Поэтому для данных, находящихся в файле, стандартные методы сортировки не подходят.

В отличие от оперативной памяти, размер внешней существенно больше и при сортировке можно использовать дополнительные контейнеры. На этом и основаны большинство подходов внешней сортировки.

### Прямое слияние

Алгоритм:

1. Последовательность $a$ разбивается на две половины $b$ и $c$.
2. Половины $b$ и $c$ сливаются в одну последовательность, при этом одиночные элементы из двух частей образуют упорядоченную пару.
3. Полученная последовательность под именем $a$ вновь делится пополам на $b$ и $c$ и далее выполняется пункт 2, но упорядоченные пары из каждой части уже сливаются в упорядоченные четвёрки.
4. Далее вновь разделение и четвёрки сливаются в восьмёрки и т.д. так до тех пор, пока не получится упорядоченная последовательность $a$.

Действие по однократной обработке всех элементов последовательности называется **фазой**.

Наименьший процесс повторение которого составляет сортировку называется **проходом**.

В примере лекции сортировка балы произведена за 3 прохода, каждая из которых состоит из фазы разделения и фазы слияния.

Поскольку на каждом проходе размер сливаемых групп увеличивается в 2 раза, то таких проходов $\log_2(n)$. При этом каждый раз проходятся все $n$ элементов дважды, а значит сложность - $O(n\log_2(n))$.

#### Усовершенствование

Можно заметить, что фаза разделения к самому процессу сортировки (сравнения элементов) отношения не имеет, поэтому сортировку можно усовершенствовать, сливая группы не в один файл $a$, а в два - по очереди.

Эти два вновь полученных файла и будут исходными для вновь сливаемых последовательностей.

## Естественное слияние

В случае прямого слияния мы не получаем никакого преимущества, даже если последовательность уже частично или полностью отсортирована.

На самом деле можно делить файлы на последовательности разной длины, если эти последовательности уже отсортированы естественным образом. В этом случае сразу сливаются не одиночные элементы, а наибольшие по длине отсортированные последовательности.

## Многопутевое слияние

Очевидно, что количество проходов можно уменьшить, если увеличить число файлов, на которые будем делить исходный - на $k$ файлов. Тогда сложность $\log_k(n)$.

## Многофазное слияние

В основе метода лежит идея отказа от понятия прохода.

Пусть у нас имеются два файла, в первом из которых $n1$ естественных серий, а во втором - $n2$, причём $n1 > n2$.

Будем сливать серии в третий файл, пока во втором они не закончатся.

Теперь, станем сливать первый и третий во второй и т.д.

Нетрудно заметить, что количество строк в таблице, а значит и количество действий по слиянию сильно зависит от количества серий в двух исходных файлах $F_1$ и $F_2$.

Лучший результат получается, когда исходные количества серий в файлах $F_1$ и $F_2$ являются соседними числами Фибоначчи.