# Список рекомендуемой литературы

1. Ахо Альфред В., Хопкрофт Джон Э., Ульман Джеффри Д. - Алгоритмы и структуры данных, 2006
2. **Кнут Д. Э. - Искусство программирования: в 3-х томах, 3е издание, 2010**
3. Вирт Никлаус - Алгоритмы и структуры данных - Нев. Диалект, 2001
# Введение
## Процесс создания программы

Схема процесса создания программы для решения прикладной задачи выглядит так:

![Процесс создания программы.png](../../%D0%9F%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%20%D1%81%D0%BE%D0%B7%D0%B4%D0%B0%D0%BD%D0%B8%D1%8F%20%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D1%8B.png#)

1. Задача описывается с помощью некоторого математического аппарата, тем самым создаётся математическая модель. На базе этой модели определяется неформальный алгоритм решения задачи.
2. На основе математической модели описываются абстрактные типы данных.
  **АТД** - это мат. модель с совокупностью операторов, определённых внутри этой модели. После определения АТД создаётся программа на псевдоязыке.
3. Для каждого АТД выбирается своя структура данных языка программирования, после чего пишется программа на этом языке.
### Пример: Раскраска географической карты

Имеется плоская географическая карта. Требуется раскрасить все государства в различные цвета так, чтобы никакие два имеющие общую границу не были окрашены в один цвет. Количество цветов по возможности должно быть небольшим.

1. Математическая модель - граф
   Неформальный алгоритм - жадный
2. АТД - граф, с определёнными на нём операциями:
	- Нахождение вершин, смежный с вершиной `i`
	- Определение цвета вершины
	- Раскраска вершины цветом `color`
	- ...
	Пишем программу:

  ```c
цикл i=1 to количество вершин {
	обнулить флаги цветов;
	цикл j=1 to количество вершин {
		если (вершина j смежная с i и вершина j выкрашена цветом color_k)
			установить флаг цвета color_k;
	}
	найти первый свободный цвет color_s;
	раскрасить вершину i цветом color_s;
}
  ```
3. Структуры - двумерный и одномерный массивы.
   Программа на языке Java.
# Линейные списки
## Стек - Stack

**Стек** - *абстрактный* тип данных, работающий по принципу `LIFO` - Last in, first out (Последним вошёл - первый вышел).

Операции:
- `nullStack` - обнуление стека
- `empty` - проверка на пустоту
- `push` - добавление элемента в стек
- `pop` - удаление элемента из стека

### Реализация стека массивом

```cpp
struct Stack1 {
	int top;
	int *data;
};

void InitStack (Stack1 &st, int capacity)
{ st.data = new int[capacity]; st.top = -1; }

void push (Stack1 &st, int value)
{ st.data[++st.top] = value; }

int pop (Stack1 &st)
{ return st.data[st.top--]; }

void nullStack (Stack1 &st)
{ st.top = -1; }

bool empty (Stack1 &st)
{ return st.top == -1; }
```
Здесь лишь не хватает проверок на переполнение стека и взятие из пустого.

### Реализация динамическим списком

Основной недостаток реализации стека массивом в том, что из-за ограниченного размера массива может произойти переполнение стека.

Реализация динамической структуры лишена этого недостатка. Размер стека ограничен только памятью компьютера.

```cpp
struct Node {
	int data;
	Node *next;
};

void initStack (Node *top) { top = NULL; }

void push (Node *top, int value) {
	Node *tmp = new Node;
	tmp->next = top;
	top = tmp;
	top->data = value;
}

int pop(Node *top) {
	Node *tmp = top;
	int d = top->data;
	top = top->next;
	delete tmp;
	return d;
}

bool empty(Node *top) { return top->next == NULL; }

void nullStack (Node *top) {
	Node *tmp;
	while (!empty(top)) {
		tmp = top;
		top = top->next;
		delete tmp;
	}
}
```

## Очередь - Queue

Очередь - линейный список, работающий по принципу `FIFO` (Первым вошёл - первый вышел).

Операции:
- `nullQueue` - обнуление очереди
- `empty` - проверка очереди на пустоту
- `add` (`enqueue`) - добавление элемента в очередь
- `del` (`dequeue`) - удаление элемента из очереди

### Реализация очереди динамическим списком

```cpp
class Queue {
private:
	struct Node {
		int data;
		Node* next;
	}
	Node *head, *tail;
public:
	Queue() { head = NULL; tail = NULL; }
	bool empty() const;
	void enqueue(int value);
	int dequeue();
	void nullQueue();
}

bool Queue::empty() const { return head == NULL; }
void Queue::enqueue(int value) {
	if (empty()) {
		head = new Node;
		head->data = value;
		head->next = NULL;
		tail = head;
	} else {
		tail->next = new Node;
		tail = tail->next;
		tail->data = value;
		tail->next = NULL;
	}
}
int Queue::dequeue() {
	if (empty()) return 0;

	int d = head->data;
	Node *tmp = head;
	head = head->next;
	delete tmp;
	return d;
}
void Queue::nullQueue() {
	Node *tmp;
	while (!empty()) {
		tmp = head;
		head = head->next;
		delete tmp;
	}
}
```

### Реализация очереди массивом

Так как размер массива ограничен, может возникнуть следующая ситуация: хвост очереди достигнет последнего элемента массива. По аналогии со стеком можно предположить, что очередь переполнена. Однако, к этому времени из головы очереди могут быть взяты несколько первых элементов и начало массива окажется пустым. То есть реально в массиве место будет.

Для решения этой проблемы будем считать массив зацикленным (или круговым), когда за последним элементом следует первый. В этом случае номер элемента следующего за `i`-тым будем вычислять по формуле: `(i+1)%n`, где `n` - размер массива.

Кроме того при круговой организации массива возникает ещё одна проблема: если не принять никаких мер, то переполненную очередь невозможно отличить от пустой - и там, и там за хвостом следует голова.  
Чтобы различать эти два состояния договорились считать очередь пустой, когда за хвостом следует голова, а переполненной, когда между хвостом и головой имеется один пустой элемент. То есть в массиве из `n` элементов поместится только `n-1` элемент очереди.
##### В виде структуры

```cpp
struct Queue {
	int head, tail, size;
	int *data;
}

void nullQueue(Queue &q)
{ q.head = 0; q.tail = q.size - 1; }

void initQueue(Queue &q, int capacity) {
	q.size = capacity + 1;
	q.data = new int[q.size];
	nullQueue(q);
}

int next(Queue &q, int n)
{ return (n + 1) % q.size; }

bool empty(Queue &q)
{ return next(q, q.tail) == q.head; }

void add(Queue &q, int value) {
	if (next(q, next(q, q.tail)) == q.head) {
		std::cout << "Queue overflow" << std::endl;
		return;
	}
	q.tail = next(q, q.tail);
	q.data[q.tail] = value;
}

int del(Queue &q) {
	if (empty(q)) {
		std::cout << "Queue is empty" << std::endl;
		return 0;
	}
	int d = q.data[q.head];
	q.head = next(q, q.head);
	return d;
}
```

#####  В виде класса

```cpp
class Queue {
	private:
		int head, tail, size;
		int *data;
	public:
		void nullQueue()
		{ head = 0; tail = size - 1; }

		void Queue(int capacity) {
			size = capacity + 1;
			data = new int[size];
			nullQueue();
		}
		
		int next(int n) const
		{ return (n + 1) % size; }
		
		bool empty() const
		{ return next(tail) == head; }
		
		void add(int value) {
			if (next(next(tail)) == head) {
				std::cout << "Queue overflow" << std::endl;
				return;
			}
			tail = next(tail);
			data[tail] = value;
		}
		
		int del() {
			if (empty()) {
				std::cout << "Queue is empty" << std::endl;
				return 0;
			}
			int d = data[head];
			head = next(head);
			return d;
		}
}
```

## Дек - deq - double ended queue

Дек - очередь, добавление и удаление элементов которой происходит с обоих концов списка.

Операции:
- Включение элемента слева
- Включение элемента справа
- Исключение элемента слева
- Исключение элемента справа
- Проверка на пустоту
- Очистка

## Двусвязные динамические списки

![Двусвязные динамические списки.png](../../%D0%94%D0%B2%D1%83%D1%81%D0%B2%D1%8F%D0%B7%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%B8%D0%BD%D0%B0%D0%BC%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5%20%D1%81%D0%BF%D0%B8%D1%81%D0%BA%D0%B8.png#)

Операции:
- Перемещение по списку в двух направлениях
- Вставка элемента слева, справа, в середину
- Удаление элемента слева, справа, из середины
# Деревья

Деревья в классике алгоритмизации растут не снизу вверх, как мы привыкли, а сверху вниз.

**Дерево** - это совокупность элементов, называемых узлами, один из которых определён как корень, и "родительских" отношений, образующих иерархическую структуру дерева.

**Рекурсивное определение:**
1. Один узел является деревом. Он же является его корнем.
2. Пусть $n$ - узел, $T_1$, $T_2$, ..., $T_k$ - деревья, с корнями $n_1$, $n_2$, ..., $n_k$ соответственно. Можно построить новое дерево, сделав $n$ родителем узлов $n_1$, $n_2$, ..., $n_k$. В этом дереве $n$ - корень, $T_1$, $T_2$, .., $T_k$ - поддеревья этого корня, $n_1$, $n_2$, ..., $n_k$ - прямые потомки (сыновья) узла $n$.

**Путём** из узла $n_1$ в узел $n_k$ называется последовательность вершин дерева $n_1$, $n_2$, ..., $n_k$, где для всех $i < k$ и $i \geq 1$ узел $n_i$ является родительским узлом для $n_{i-1}$.  
**Длиной пути** называется число на единицу меньшее количества узлов, составляющих этот путь.

Если существует путь из узла $a$ в узел $b$, то
- Узел $a$ - предок узла $b$.
- Узел $b$ - потомок узла $a$.

Считается что любой узел является одновременно предком и потомком самому себе. Таким образом корень дерева - узел не имеющий других предков.

Узел, не имеющий других потомков, кроме себя называется **листом** или терминальной вершиной дерева.

**Высотой узла** дерева называется длина самого длинного пути от этого узла до некоторого листа.  
Высота дерева совпадает с высотой корня.

**Глубиной узла** называется длина пути от корня до этого узла.

Дерево не имеющее ни одного узла называется **нулевым деревом**.


#### Пример дерева

![Пример дерева.png](../../%D0%9F%D1%80%D0%B8%D0%BC%D0%B5%D1%80%20%D0%B4%D0%B5%D1%80%D0%B5%D0%B2%D0%B0.png#)

Корень дерева - $A$.  
Листья дерева: $E$, $F$, $J$, $K$, $H$, $I$.  
Высота дерева: $3$.

## Способы обхода деревьев

**Способ обхода** - это упорядочение узлов дерева по некоторому признаку/правилу.
### Классический

Обычно используют три способа обхода: прямой, обратный, симметричный.

**Правила обхода:**
- Если дерево $T$ является нулевым, то в список обхода заносится пустая запись.
- Если дерево $T$ состоит из одного узла, то в список обхода заносится этот узел.
- Пусть $T$ - дерево с корнем $n$ и поддеревьями $T_1$, $T_2$, ..., $T_k$.  
	Тогда для различных способов обхода имеем:
	1. При **прямом обходе** сначала посещается корень $n$, затем поддеревья $T_1$, $T_2$, ..., $T_k$ также в прямом порядке.  
		Для дерева из примера, порядок: $A,B,E,F,C,G,J,K,D,H,I$.
	2. При **обратном обходе** сначала в обратном порядке обходится поддерево $T_1$, затем $T_2$, ..., $T_k$ также в обратном порядке. Последним посещается корень $n$.  
		Порядок дерева из примера: $E,F,B,J,K,G,C,H,I,D,A$.
	3. При **симметричном обходе** сначала в симметричном порядке обходится поддерево $T_1$, затем корень $n$, после чего - поддеревья $T_2$, ..., $T_k$ также в симметричном порядке.  
		(Лево, корень, остальное)  
		Порядок примера: $E,B,F,A,C,J,G,K,H,D,I$.

## Бинарные деревья

Дерево, у каждого узла которого может быть не более двух прямых потомков называется бинарным или двоичным деревом.

Бинарное дерево называется **сбалансированным**, если высоты левого и правого поддеревьев любого узла дерева отличаются друг от друга не более, чем на единицу.  
**Идеально сбалансированное** дерево - разность высот для любого из узлов равна нулю.

### Способы представления бинарных деревьев

#### Одномерный массив

Корень дерева - нулевой элемент массива.
Левый потомок корня - первый элемент.
Правый потомок корня - второй элемент.
...
Потомки элемента $i$ - хранятся под номерами:
- $2i+1$ - левый
- $2i+2$ - правый.

#### Пример:
![Небольшое дерево.png](../../%D0%9D%D0%B5%D0%B1%D0%BE%D0%BB%D1%8C%D1%88%D0%BE%D0%B5%20%D0%B4%D0%B5%D1%80%D0%B5%D0%B2%D0%BE.png#)

Хранится в виде:

| 0   | 1   | 2   | 3   | 4   | 5   |
| --- | --- | --- | --- | --- | --- |
| $A$ | $B$ | $C$ | $D$ | $E$ | $F$   |

### Динамическая структура данных

```cpp
struct Node {
	int data;
	Node *left, *right;
}
```
![Пример ноды дерева структурой.png](../../%D0%9F%D1%80%D0%B8%D0%BC%D0%B5%D1%80%20%D0%BD%D0%BE%D0%B4%D1%8B%20%D0%B4%D0%B5%D1%80%D0%B5%D0%B2%D0%B0%20%D1%81%D1%82%D1%80%D1%83%D0%BA%D1%82%D1%83%D1%80%D0%BE%D0%B9.png#)
```cpp
void create(Node *&node, int n) {
	if (node != NULL)
		return;
	node = new Node;
	node->data = n;
	node->left = NULL;
	node->right = NULL;
}

void print(Node *node) {
	if (!node)
		return;
	std::cout << node->data << " ";
	print(node->left);
	print(node->right);
}
```

## Дерево Хаффмана

Каждый узел дерева Хаффмана будет состоять из пяти полей: символ, вероятность его вхождения, указатели на левое и правое поддеревья, а также указатель на родительский узел. Этот указатель нужен для того, чтобы быстро найти код любого символа.

Заведём два одномерных массива: `trees`, где будем собирать дерево Хаффмана, пока оно не останется одно, и `symbols` - указатели на все символы для быстрого нахождения кода.

```cpp
class HaffmanTree {
private:
	struct Node {
		double p;
		char c;
		Node *left, *right, *parent;
	};
	Node *trees[256], *symbols[256];
	int size;
public:
	HaffmanTree(int size) { this->size = size; }
	void read() {
		for (int i = 0; i < size; i++) {
			trees[i] = new Node;
			symbols[i] = trees[i];
			std::cout << "Symbol: ";
			std::cin >> trees[i]->c;
			std::cout << "Probability: ";
			std::cin >> trees[i]->p;
			trees[i]->left = NULL;
			trees[i]->right = NULL;
			trees[i]->parent = NULL;
		}
	}
	void printCode() {
		if (size == 1) {
			std::cout << symbols[0]->c << " - " << 0 << std::endl;
			return;
		}
		for (int i = 0; i < size; i++) {
			Node *tmp = symbols[i];
			string code = "";
			while (tmp->parent != NULL) {
				if (tmp->parent->left == tmp)
					code = "0" + code;
				else
					code = "1" + code;
				tmp = tmp->parent;
			}
		}
		
	}
	void makeTree (int col) {
		if (col <= 1)
			return;
		double minp1, minp2 = 1;
		int n1, n2 = 0;
		for (int i = 0; i < size; i++)
			if (trees[i] != NULL && trees[i]->p < minp1) {
				minp1 = trees[i]->p;
				n2 = i;
			}
		for (int i = 0; i < size; i++)
			if (trees[i] != NULL && trees[i]->p < minp2 && i != n1) {
				minp1 = trees[i]->p;
				n2 = i;
			}
		Node *tmp = new Node;
		tmp->left = trees[n1];
		tmp->right = trees[n2];
		treen[n1]->parent = tmp;
		trees[n2]-> parent = tmp;
		tmp->p = trees[n1]->p + trees[n2]->p;
		trees[n1] = tmp;
		trees[n2] = NULL;
		makeTree(col-1);
	}
};
```
# Метод полного перебора

Многие задачи заключаются в выборе одного или нескольких вариантов из набора дискретных данных. Один из самых простых способов решения таких задач - перебрать все возможные варианты и выбрать из них необходимый.

Главное достоинство такого метода - гарантированно полное решение задачи.  
Основной недостаток - большое время выполнения алгоритма при увеличении количества исходных данных.

## Перебор циклами

Главный недостаток перебора циклами заключается в том что можно заранее не знать сколько циклов вкладывать друг в друга. То есть их количество может зависеть от длины исходных данных.

##### Пример: Найти количество счастливых автобусных билетов

```cpp
int cnt = 0;
for (int a = 0; a <= 9; a++)
  for (int b = 0; b <= 9; b++)
    for (int c = 0; c <= 9; c++)
      for (int d = 0; d <= 9; d++)
        for (int e = 0; e <= 9; e++)
          for (int f = 0; f <= 9; f++)
            if ((a+b+c) == (d+e+f))
              cnt++;
```

## Полный P-ичный перебор

Каждому перебираемому элементу ставится в соответствии цифра в P-ичной системе счисления. Предполагается, что каждый элемент может находиться в $P$ различных состояниях. Тогда перебор всех вариантов потребует $P^n$ итераций, где $n$ - количество исходных данных.

Дано $N$ объектов, каждому из которых поставлена в соответствии некоторая стоимость. Разделить объекты на две группы так, чтобы разность стоимостей между группами была минимальной.

Данная задача решается полным двоичным перебором. За каждым объектом закрепляется двоичная цифра:
- `0` - объект попадает в первую группу
- `1` - объект попадает во вторую группу

Перебор сводится к просмотру всех чисел разрядности $N$ в двоичной системе счисления.

```cpp
void plus(int *m, int n) {
  int i = n;
  while (m[i] == 1)
    m[i--] = 0;
  m[i] = 1;
}
  
int main() {
  const int n = 5;
  int min = 15;
  int m[n+1] = {0, 1, 2, 3, 4, 5},
      bin[n+1] = {0, 0, 0, 0, 0, 0};
  while (bin[0] == 0) {
    int s1 = 0, s2 = 0;
    for (int i = 1; i <= n; i++)
      if (bin[i] == 0) s1 += m[i];
      else s2 += m[i];
  
    if (abs(s1 - s2) < min)
      min = abs(s1 - s2);
  
    plus(bin, n);
  }
  return 0;
}
```

## Рекурсивный перебор

Дан квадратный числовой массив

Найти такой путь из левого верхнего угла массива в правый нижний, чтобы сумма чисел по данному пути была максимальной.

Из каждого элемента массива допустимо двигаться только вправо или вниз.

Идея заключается в следующем: из каждой клетки массива, если это возможно, будем пытаться идти сначала вниз, потом вправо.

Когда дойдём до правого нижнего элемента массива, найденную по пути сумму сравним с максимальной и если найденная оказалась больше, запомним её в максимум.

```cpp
void poisk (int **m, int n, int i, int j, int s, int _max) {
	s += m[i][j];
	if (i == n-1 && j == n-1 && s > _max)
		_max = s;
	if (i < n-1) poisk(m, n, i+1, j, s, _max);
	if (j < n-1) poisk(m, n, i, j+1, s, _max);
}
```

## Динамическое программирование

Данный метод был описан в 1960х с целью ускорения решения многих задач выбора.

Суть метода в следующем: большая задача делится на подзадачи. В начале, решается подзадача минимального размера, далее, на её основе - подзадача следующего размера, и так далее, пока не будет решена искомая задача, размера $n$.  

При этом должно выполняться условие: предыдущие подзадачи не пересчитываются. То, что хорошо локально, будет хорошо и глобально для большой задачи.

На каждом шаге пересчёта выбор варианта производится в соответствии с так называемым принципом оптимальности.

### Пример 1

Предыдущий пример можно решить динамическим программированием. Для этого заводится ещё один массив размером $n \times n$.

Ясно, что если массив $a$ имеет размер $1 \times 1$ (минимальная подзадача), то набранная сумма будет равна элементу `a[0][0]` - занесём её в `b[0][0]`.

Если от элемента `a[0][0]` станем двигаться вправо, то сумма изменится на `b[0][0] + a[0][1]`. И так можно продолжить для всей первой строки и первого столбца массива.

Для всех остальных элементов: `b[i][j] = max(b[i-1][j], b[i][j-1]) + a[i][j]` - это "принцип оптимальности".

В элементе массива `b[n-1][n-1]` получим значение искомой суммы.

Сам путь можно найти двигаясь от элемента `b[n-1][n-1]` к элементу `b[0][0]` по "жадному" алгоритму.

### Пример 2

##### Задача о министерстве.

Вовочке нужно подписать документ у министра. Министр подписывает бумагу, если на ней имеется подпись любого работника с последнего этажа министерства.

Каждый работник на каждом этаже сидит в отдельном кабинете и ставит подпись только в том случае, если на бумаге уже стоит подпись работника либо из кабинета под ним, либо из одного из соседних кабинетов. На первом этаже бумагу сразу подписывает любой работник.

За свою подпись каждый работник берёт некоторую сумму. Известны суммы, которые берёт каждый работник в каждом кабинете.

Найти такой путь Вовочки по министерству, чтобы сумма была минимальной.

Количество этажей $1 \le n \le 100$.

##### Решение

Для решения можно использовать три двумерных массива.

В массиве $a$ будем хранить суммы, которые берут клерки в каждом кабинете.

Массив $b$ - это расчёт лучшего значения суммы для каждого кабинета. Рассчёт будет вестись по формуле:  
`b[i][j] = min(a[i][j] + b[i-1][j], a[i][j] + b[i][j-1], a[i][j] + b[i][j+1])`   
по принципу оптимальности.

В массиве $c$ будем отмечать откуда мы пришли в каждый кабинет:
- Снизу - 0
- Справа - -1
- Слева - 1

При реализации двумерные массивы $a$ и $b$ можно заменить на одномерные, считывая в $a$ значения текущего этажа и просчитывая $b$ для вновь считанного этажа на основании уже имеющихся в $b$ данных.

##### Программа

```cpp
int currentfloor[M];
int bestfloor[M];
int direction[N][M];
ifstream f("input.txt");
int n, m;
f >> n >> m;
for (int i = 0; i < m; i++)
	bestfloor[i] = 0;
for (int i = 0; i < n; i++) {
	for (int j = 0; j < m; j++) {
		f >> currentfloor[j];
		bestfloor[j] += currentfloor[j];
		direction[i][j] = 0;
	}
	for (int j = 1; j < m; j++) {
		if (bestfloor[j-1] + currentfloor[j] < bestfloor[j]) {
			bestfloor[j] = bestfloor[j-1] + currentfloor[j];
			direction[i][j] = -1;
		}
		if (bestfloor[j+1] + currentfloor[j] < bestfloor[j]) {
			bestfloor[j] = bestfloor[j+1] + currentfloor[j];
			direction[i][j] = 1;
		}
	}
}
```


### Пример 3

##### Задача о рюкзаке

Имеется $n$ видов объектов массами $m_1$, $m_2$, ..., $m_n$ и стоимостями $s_1$, $s_2$,, ..., $s_n$. Объектов каждого вида неограниченное количество.

Также имеется рюкзак, который может вместить по массе не более $M$ единиц.

Требуется узнать сколько предметов каждого вида нужно положить в рюкзак, чтобы суммарная стоимость предметов в рюкзаке была наибольшей.

Все величины $m_i$, $s_i$ и $M$ - целые числа.

##### Решение

Будем заполнять рюкзаки вместимостью 0, 1, ..., $M$ объектами первого вида, высчитывая при этом стоимость каждого рюкзака.

На следующем шаге в каждый из рюкзаков будем пытаться поместить объекты второго вида в количестве 0, 1, ..., $M$, при этом может остаться ещё какая-то масса, которую рюкзак выдержит. Её надо заполнить предметами первого вида, а эта стоимость уже просчитана на предыдущем шаге. Осталось из всех вариантов загрузки предметов второго вида выбрать наилучший и запомнить его. И так далее до загрузки рюкзака вместимостью $M$ предметами $n$-го вида.# Другие алгоритмы решения задач выбора
## Жадный алгоритм

**Жадный алгоритм** - алгоритм, заключающийся в принятии локально оптимальных решений на каждом этапе, допуская, что конечное решение также окажется оптимальным. Известно, что если структура задачи является матроидом, тогда применение **жадного алгоритма** выдаст глобальный оптимум.

Пусть имеем пару множеств: $(D, F)$  
$D=\{d_1,d_2, ... ,d_n\}$  - конечное множество.  
$F = \{f_1,f_2, ..., f_k\}$ - совокупность подмножеств множества $D$.

Пара $(D,F)$ является **матроидом**, если она обладает двумя свойствами:
1.  $(f \in F\ \&\ h \in f) => h \in F$
2. $f, g \in F,\ \ |f| = u,\ \ |g| = u+1$, тогда есть элемент $e \in g$ такой, что:
	- $e \cup f \in F$
	- $|e \cup f| = u+1$

### Теорема Радо-Эдмондса

Применение жадного алгоритма к задаче выбора, множеством траекторий которой является система подмножеств $F$ некоторого множества $D$, даёт точный результат тогда и только тогда, когда пара $(F, D)$ - матроид.

## Генетические алгоритмы

**Генетический алгоритм** - это эвристический алгоритм поиска, используемый для решения задач оптимизации и моделирования путём случайного подбора, комбинирования и вариации искомых параметров с использованием механизмов, аналогичных естественному отбору в природе.


## Муравьиные алгоритмы

**Муравьиный алгоритм** - алгоритм оптимизации подражанием муравьиной колонии (ant colony optimization, ACO). Один из эффективных полиномиальных алгоритмов для нахождения приближённых решений задачи коммивояжёра, а также решения аналогичных задач поиска маршрута на графах.

## Метод ветвей и границ

- Предназначен в первую очередь для решения NP-трудных оптимизационных задач.
- Сочетание двух операций:
	- Ветвление
	- Оценка верхней/нижней границы и "отсечение" неперспективной ветви

Даёт гарантированно лучший результат, но может привести к полному перебору.# Алгоритмы теории графов

Любое конечное множество точек (вершин), некоторые из которых попарно соединены стрелками (дугами) можно рассматривать как **граф**.

Две вершины могут быть соединены несколькими дугами, идущими в одном направлении - такие дуги называются **кратными дугами**, а граф, который содержит кратные дуги - **мультиграфом**.

В дальнейшем будем говорить о простых графах не содержащих кратных дуг.


Простым ориентированным **графом** называется пара объектов:  
$G = (V, E)$  
$V$ - конечное множество.  
$E$ - конечное подмножество декартового произведения $V \times V$.  

Множество $V$ называется множеством вершин графа $G$.  
Множество $E$ называется множеством дуг графа $G$.

Дуга представляется в виде упорядоченной пары $(V1, V2)$, где $V1$ - начало дуги, а $V2$ - конец. При этом говорят, что дуга $(V1, V2)$ ведёт из вершины $V1$ в вершину $V2$, а вершина $V2$ смежная с вершиной $V1$.


Дуга $u \in E$ и вершина $v \in V$ называются **инцидентными**, если дуга $u$ либо входит в вершину $v$, либо выходит из неё.

**Степенью вершины** $v$ называется количество дуг (рёбер), инцидентных с этой вершины.

**Путём** в графе $G$ называется последовательность вершин $v_1, v_2, ...$ для которых существуют дуги $(v_1, v_2), (v_2, v_3), ..., (v_{n-1}, v_n)$ - если по дугам мы можем пройти от вершины $v_1$ до $v_n$.

**Длиной пути** называют количество дуг, составляющих путь.

Иногда каждой вершине графа ставят в соответствии некоторую стоимость или вес. Такие графы называются **взвешенными**, а длиной пути является сумма стоимостей всех дуг, составляющих этот путь.

Путь называется **простым**, если все вершины в нём за исключением быть может первой и последней, присутствуют один раз.

**Цикл** это простой путь в графе длиной не менее единицы у которого первая и последняя вершины совпадают.

Цикл, проходящий через все вершины графа называется **гамильтоновым**.

Цикл, проходящий через все дуги (рёбра) графа по одному разу называется **эйлеровым**.

Граф $G$ называется **сильносвязным**, если для любых двух вершин $V_i, V_j \in V$ таких, что $V_i \ne V_j$ существует путь из $V_i$ в $V_j$. (Из любой вершины можно пройти в любую).

**Компонентой связности** графа $G$ называется подграф $G'$, обладающий двумя свойствами:

1. $G'$ сильносвязен.
2. $G'$ обладает свойством максимальности.  
	(Если добавить нечего, что заставит граф остаться компонентой связности - граф максимален).

### Пример графа

![Pasted image 20231127131202.png](../../Pasted%20image%2020231127131202.png#)

$$V = \{V1,V2,V3,V4\}$$
$$E=\{(V1,V2),(V2,V1),(V2,V3),(V3,V4)\}$$
### Симметрические графы

Граф $G$ называется симметрическим, если для любых $i$ и $j$, $(V_i, V_j) \in E => (V_i, V_j) \in G$.

Чаще всего в симметрических графах дуги $(V_i, V_j)$ и $(V_j, V_i)$ заменяют рёбрами и такой граф называется неориентированным.# Способы представления графов

## Матрица смежности

**Матрицей смежности** для графа $G$ равного паре $V$ $E$, где $V = \{v_1, v_2, ..., v_n\}$, называется матрица $A$ размером $n \times n$, где $a_{ij} = 1$, тогда и только тогда, когда существует дуга $(i, j)$. Все остальные элементы матрицы $A$ равны нулю.

В случае взвешенного графа матрица смежности часто заменяется матрицей стоимости.

Основным плюсом использования матрицы смежности является прямой доступ к каждому элементу. То есть информацию о дуге $(i, j)$ можно получить за одну элементарную операцию.

Главный минус - размер матрицы пропорционален $n^2$, где $n$ - количество вершин графа. Следовательно требуется большое количество памяти и большое количество времени поиска по матрице.
##### Пример

$$
\begin{pmatrix}
0 & 1 & 0 & 0\\
1 & 0 & 1 & 0\\
0 & 0 & 0 & 1\\
0 & 0 & 0 & 0
\end{pmatrix}
$$

![Pasted image 20231127131202.png](../../Pasted%20image%2020231127131202.png#)


## Списки смежности

**Списки смежности** представляют собой одномерный массив указателей $i$-й элемент которого содержит адрес списка вершин, смежных с $i$-й.

| Элемент | Список       |
| ------- | ------------ |
| 1       | $[v_2]$        |
| 2       | $[v_1, v_3]$ |
| 3       | $[v_4]$        |
| 4       | -            |

Списки смежности имеют преимущество перед матрицей смежности только в том случае, если граф сильно разрежён (при большом количестве вершин малое количество дуг).

Количество дуг: $$k = \frac{n(n-1)}{2}$$


## Задача о кёнигсбергских мостах

Город Кёнигсберг стоит по обоим берегам реки Преголь и её двух островах. Берега и острова соединены семью мостами.

Вопрос: Можно ли выйти из дома, прогуляться по каждому мосту лишь один раз и вернуться домой? И если да, то как это сделать?

![Pasted image 20231204125243.png](../../Pasted%20image%2020231204125243.png#)

Ответ на этот вопрос дал немецко-российский учёный Леонард Эйлер.

Схему Кёнигсберга можно изобразить в виде графа:

![Pasted image 20231204125615.png](../../Pasted%20image%2020231204125615.png#)

Вершины графа - берега и острова. Рёбра - мосты.  
Задача сводится к нахождению в графе эйлерова цикла.

Теорема: эйлеров цикл в графе существует тогда и только тогда, когда степени всех его вершин чётные.

### Алгоритм нахождения эйлерова цикла

1. Выбрать произвольно некоторую вершину $v_0$.
2. Выбрать произвольно некоторое ребро $u$, инцидентное вершине $v_0$ и пометить его номером 1.
	Будем считать помеченное ребро пройденным.
3. Каждое пройденное ребро помечать номером на единицу больше предыдущего и вычёркивать его из графа.
4. Находясь в вершине $v_i$ не выбирать ребро $(v_i, v_0)$, если это возможно.
5. Находясь в вершине $v_i$ не выбирать ребро, которое является перешейком (при удалении перешейка граф распадётся на две области связности).
6. После того, как в графе будут занумерованы все рёбра цикл $(u_1, u_2, ..., u_k)$, образованный рёбрами с номерами 1, 2, ..., $k$ является эйлеровым циклом в графе.

# Обход графа в ширину (волновой обход графа)

**Обход в ширину** фактически позволяет найти путь минимальной длины от вершины А к любой другой вершине в произвольном невзвешенном графе $G$.

Если рёбра/дуги графа имеют вес/стоимость, обход в ширину данную задачу не решает.

## Задача

Лабиринт состоит из множества комнат одинакового размера. Некоторые из комнат соединены дверями.

Определить можно ли пройти из комнаты А в комнату Б и, если да, вычислить за какое минимальное количество перемещений.

Математической моделью данной задачи является неориентированный граф.

Проще всего задача решается обходом графа в ширину, начиная с вершины А.

## Алгоритм

1. Присваиваем вершине А метку `0`.
2. Всем вершинам, смежным с вершиной А, присваивается метка `1`.
3. Процесс продолжается следующим образом: всем непомеченным вершинам, смежным с `1`, присваивается `2` и т.д.
4. Если помечена вершина Б, алгоритм завершается.  
	Метка вершины Б - минимальное количество шагов от А до Б.
5. Если на некотором шаге ни одна вершина не получила новую метку, а вершина Б так и не помечена, значит пути из вершины А в вершину Б не существует.

Если необходимо найти не только количество шагов, но и **путь**, будем двигаться от вершины Б к одной из смежных вершин с меткой на единицу меньшей данной вершины.

## Программа

```java
public int makeWave (int a, int b) {
  int path[] = new int[vertCount+1];
  for (int i = 1; i <= vertCount; i++)
    path[i] = -1;
  path[a] = 0;
  int currentStep = 1;
  int i = 1;
  boolean isMetNewVertice = false
  boolean isEverythingMarked = false;
  do {
    while (i <= vertCount && path[i] != currentStep-1) i++;
    if (i <= vertCount) {
      isMetNewVertice = true;
      for (int j = 1; j <= vertCount; j++)
        if (graph[i][j] == 1 && path[j] == -1)
          path[j] = currentStep;
      i++;
    } else if (isMetNewVertice) {
      i = 1;
      isMetNewVertice = false;
      currentStep++;
    } else {
      isEverythingMarked = true;
    }
  } while (!isEverythingMarked);
  
  return path[b];
}
```
# Алгоритм Дейкстры

## Задача

Имеется произвольный граф каждому ребру которого присвоена некоторая неотрицательная стоимость.

Требуется найти путь минимальной стоимости из вершины А в вершину Б.

## Алгоритм

1. Присвоим вершине А метку `0`, объявив метку постоянной.
	Остальным вершинам присвоим метку +бесконечность, считая эти метки временными.
2. Берём вершину, получившую постоянную метку на предыдущем шаге и для каждой смежной с ней вершины $g$ пересчитываем временную метку по формуле: `label[j] = min(label[j], label[i] + path[i][j])`.
3. Из всех временных меток выбираем минимальную, делаем её постоянной, и если это не метка вершины Б, возвращаемся к пункту 2, иначе пункт 4.
4. Постоянная метка вершины Б - стоимость искомого минимального пути.

Сам **путь** можно найти двумя способами:
- Вычитать длину ребра и искать совпадение значения с меткой.
- Завести ещё одну структуру - одномерный массив, в который будут записаны вершины, через которые перезаписаны метки.

## Программа

```java
public class Deikstra {
  int[][] graph;
  int size;
  class Label {
    int value;
    int isPermanent;
  }
  Label[] labels;
  
  public int findPath(int a, int b) {
    labels[a].value = 0;
    labels[a].isPermanent = 1;
    int i = a;
    for (int j = 1; j <= size; j++) {
      if (j != 1) {
        labels[j].value = Integer.MAX_VALUE;
        labels[j].isPermanent = 0;
      }
    }
  
    while (i != b) {
      for (int j = 1; j <= size; j++) {
        if (graph[i][j] != 0 && labels[j].isPermanent == 0) {
          if (labels[j].value > labels[i].value + graph[i][j]) {
            labels[j].value = labels[i].value + graph[i][j];
          }
        }
        int min = Integer.MAX_VALUE;
        int nmin = 0;
        for (int j = 1; j <= size; j++) {
          if (labels[j].value < min && labels[j].isPermanent == 0) {
            min = labels[j].value;
            nmin = j;
          }
        }
        labels[nmin].isPermanent = 1;
        i = nmin;
      }
    }
    return labels[b].value;
  }
}
```
# Алгоритм Флойда

Данный алгоритм использует матрицу $A$ размером $n \times n$ в которой находятся длины кратчайших путей между всеми парами вершин.

В начале матрица $A$ совпадает с матрицей стоимости, но если дуга $i-j$ отсутствует то $A[i][j]=+ \infty$, все $A[i][i] = 0$.

Над матрицей $A$ выполняется $n$ итераций. После $k$-й итерации $A[i][j]$ содержит стоимость кратчайшего пути из вершины $i$ в вершину $j$, который не проходит через вершины с номерами большими $k$.

$$A_k[i][j] = min(A_{k-1}[i][j], A_{k-1}[i][k]+A_{k-1}[k][j])$$


```cpp
for (int k = 1; k <= size; k++)
	for (int i = 1; i <= size; i++)
		for (int j = 1; j <= size; j++)
			if (a[i][k] + a[k][j] < a[i][j])
				a[i][j] = a[i][k] + a[k][j];
```
# Транзитивное замыкание

В ряде случаев интерес представляет лишь факт того, существует ли путь из вершины $i$ в $j$ или нет.

Задачу конечно можно решить Алгоритмом Флойда, однако несколько раньше была решена Уоршаллом. 

Требуется преобразовать матрицу смежностей $A$ таким образом, что $A[i][j] = 1$ тогда и только тогда, когда существует путь из вершины $i$ в вершину $j$. Все остальные элементы равны нулю.

Такая матрица называется Транзитивным замыканием графа $G$ и если считать `0` - `false` и `1` - `true`, то по аналогии с Алгоритмом Флойда матрица будет вычислена формулой:

$$A_k[i][j] = A_{k-1}[i][j]\ ||\ (A_{k-1}[i][k]\ \&\&\ A_{k-1}[k][j])$$
# Обход графа в глубину

Пусть имеется граф $G$ в котором первоначально все вершины помечены "не посещалась".

Обход в глубину начинается с выбора начальной вершины $v_0$ графа $G$, которая помечается "посещалась".

Затем для каждой вершины смежной с $v_0$ ещё не посещённой рекурсивно повторяется код в глубину.

Когда все вершины, которые можно посетить из $v_0$ будут помечены, обход завершается. Если при этом в графе остались вершины ещё не посещённые, можно выбрать одну из них и повторить обход снова, продолжая так до тех пор, пока все вершины не будут помечены.


![Pasted image 20240213161126.png](../../Pasted%20image%2020240213161126.png#)



Запись матрицы в виде текстового файла:

```
7
0 1 1 1 0 0 0 1 0 0
1 0 0 1 0 0 0 0 0 0
1 0 0 1 0 0 0 0 0 0
1 1 1 0 0 0 0 0 0 0
0 0 0 0 0 1 1 0 0 0
0 0 0 0 1 0 1 0 0 0
0 0 0 0 1 1 0 0 0 0
1 0 0 0 0 0 0 0 1 1
0 0 0 0 0 0 0 1 0 1
0 0 0 0 0 0 0 1 1 0
```

Чтение матрицы:

```cpp
#include <iostream>
#include <fstream>
using namespace std;

void main() {
	ifstream f("input.txt");
	int a[100][100];
	int n;
	f >> n;
	for (int i = 0; i < n; i++)
		for (int j = 0; j < n; j++)
			f >> a[i][j];
	f.close();
}
```

При обходе графа в глубину, помечаются лишь некоторые рёбра. Они составляют в графе так называемый глубинный остовный лес.

## Поиск циклов в графе

Если при обходе графа в глубину встречается "обратная" дуга (ведущая к уже помеченной вершине), то значит в графе есть цикл.

И наоборот, если в графе имеется цикл, то при обходе в глубину обязательно встретится "обратная" дуга.

А это значит, что обход графа в глубину можно использовать для поиска циклов в графе.# Сильная связность в графе

Сильно связной компонентой графа $G$ называется множество вершин, в котором существует путь из любой вершины в любую другую.

Алгоритм:

1. Производится обход в глубину графа $G$. При этом вершины помечаются в порядке обратном рекурсивному обходу.
2. Конструируем новый граф $G'$, обращая направление всех дуг графа $G$.
3. Выполняется обход в глубину графа $G'$, начиная с вершины помеченной номером $n$ на первом шаге.
4. Если не все вершины обойдены - продолжаем с вершины, имеющий больший номер.
5. Глубинный остовный лес, полученный на шаге 3, образует компоненты сильной связности графа $G$.
# Остовное дерево минимальной стоимости

## Задача

В городе $n$ существует $N$ предприятий, которые длительное время тянули линии связи от одного к другому без разбора.

Когда руководители предприятий встретились между собой, выяснили, что некоторые линии являются необязательными.

Известны длины уже протянутых линий между предприятиями. Необходимо узнать какие из них можно убрать, чтобы при этом длина убранных линий была максимальной, а возможность связи между предприятий осталась та же.

Данная задача фактически сводится к нахождению в графе остовного дерева минимальной стоимости.

## Алгоритм

Задача решается несколькими алгоритмами. Один из них - алгоритм Прима.

1. Заведём два множества. 
	Первое, $V$ - множество всех вершин.  
	Второе, $U$ - пустое множество.
2. Поместим в множество $U$ произвольную вершину из $V$.
3. Найдём в множестве $V \backslash U$ такую вершину, которая соединяется с одной из вершин множества $U$ ребром минимальной стоимости.
4. Запомним это ребро и помещаем найденную вершину во множество $U$.
5. Если множество $U \neq V$, повторяем с пункта 3.
6. Иначе, множество помеченных рёбер и будет составлять остовное дерево графа минимальной стоимости.

# Способы сортировки последовательностей

**Сортировка** - перемещение элементов последовательности в порядке возрастания (неубывания) или убывания (невозрастания).

## Введение
### Области применения задачи сортировки

1. Задача группировки.
2. Поиск общих элементов в двух или более последовательностях.
3. Задача поиска.

### Постановка задачи

Пусть необходимо упорядочить $N$ записей: $R_1, R_2, ..., R_n$.  
Пусть каждая запись $R_i$ имеет ключ $k_i$, который и управляет процессом сортировки (в дальнейшем будем сортировать только ключи).

Введём на множестве ключей отношение порядка "меньше" такое, что для всех $a,b,c$ выполняются два условия:
1. Существует одно и только одно утверждение: $a < b$, $a > b$, $a = b$.
2. $a < b$ и $b < c$ $\Rightarrow$ $a < c$.

Любое множество с данным отношением подлежит сортировке в выбранном нами смысле. То есть записи упорядочиваются: $R_{i_1}, R_{i_2}, ..., R_{i_n}$, где $k_{i_1} \leq k_{i_2} \leq ... \leq k_{i_n}$.


## Базовые методы сортировки

Среди методов сортировки массивов выделяют три базовых:

- Метод прямого включения
- Метод прямого выбора
- Метод прямого обмена

### Метод прямого выбора

Среди всех элементов ищется минимальный и меняется местами с первым. Далее минимальный ищется среди оставшихся и меняется местами со вторым.
И так далее, пока массив не будет отсортирован.

Сложность метода на любом массиве будет $O(n^2)$, так как в методе два вложенных цикла: первый проходит $n-1$ итерацию, внутренний - $n-1, n-2, ...$ итераций.

Алгоритм простой и его реализация тоже будет проста:

```cpp
void selection (int* arr, int n) {
	for (int i = 0; i < n-1; i++) {
		int min = arr[i], min_index = i;
		for (int j = i+1; j < n; j++)
			if (arr[j] < min)
				min = arr[j],
				min_index = j;
		m[index] = m[i];
		m[i] = min;
	}
}
```

### Метод прямого включения (вставки)

$i$-й элемент вставляется среди предыдущих на подходящее для него место. Эта процедура проводится для всех элементов массива, начиная со второго и до последнего.

В худшем случае как и в среднем сложность - $O(n^2)$. Однако в лучшем случае (уже отсортированный массив) - $O(n)$, так как тело цикла `while` не будет выполняться ни разу.

```cpp
void insertion (int* arr, int n) {
	for (int i = 1; i < n; i++) {
		int el = arr[i], index = i;
		while (index != 0 && el < arr[index - 1])
			arr[index] = arr[index - 1], index--;
		arr[index] = el;
	}
}
```

### Метод прямого обмена

Также известен как метод пузырька.

1. Последний элемент массива сравнивается с предпоследним и если последний меньше - меняются местами.
2. Предпоследний элемент сравнивает с третьим с конца и снова упорядочиваются.
3. Так далее до начала массива. В результате на первом месте окажется минимальный элемент.
4. Процедура повторяется, но движемся до второго, третьего элемента и т.д.

Два вложенных цикла `for` дают сложность на любом входном массив $O(n^2)$.

Среди трёх базовых методов этот - самый медленный.

Алгоритм называется методом пузырька, так как если представить массив вертикальным, то элементы, имеющие меньшие значения на каждом проходе как лёгкие пузырьки в воде поднимаются вверх.

```cpp
void bubble(int *arr, int n) {
	for (int i = 0; i < n - 1; i++) {
		for (int j = n - 1; j > i; j--)
			if (arr[j] < arr[j - 1]) swap(arr[j], arr[j - 1]);
	}
}
```

## Улучшенные методы сортировки

### Шейкерная сортировка

Данный метод является улучшением пузырьковой сортировки.

Улучшения:

1. Запоминать были или нет перестановки в процессе некоторого прохода. Если нет, сортировку можно завершить.
2. Запоминать не только сам факт перестановки, но и место последнего обмена. Ясно, что после этого места массив уже отсортирован.
3. Проводить сортировку последовательно в двух направлениях по массиву. Сначала от конца к началу, а затем от начала к концу.

В лучшем случае на уже отсортированном массиве сложность будет $O(n)$, так как будет выполнен один раз первый цикл `for`, после чего `left` станет равен `right + 1`.

Однако в худшем случае (массив отсортирован в обратном порядке) сложность всё равно $O(n^2)$.

```cpp
void shaker(int *arr, int n) {
    int left = 1, right = n - 1, k = right;
    do {
        for (int j = right; j >= left; j--)
            if (arr[j] < arr[j - 1]) {
                swap(arr[j], arr[j - 1]);
                k = j;
            }
        left = k + 1;
  
        for (int j = left; j <= right; j++)
            if (arr[j] > arr[j - 1]) {
                swap(arr[j], arr[j - 1]);
                k = j;
            }
        right = k - 1;
    } while (left < right);
}
```

### Сортировка Шелла

Сортировка даёт выигрыш по сравнению с классическими методами, потому что на каждом шаге сортируется минимум элементов, либо элементы уже отсортированы.

В классической сортировке Шелла расстояние между элементами меняются как кратные чётные числа. На самом деле это не лучший вариант.

До сих пор окончательно неизвестно при каких расстояниях скорость - самая быстрая. Но точно известно, что они не должны быть множителями друг друга.

"Хороший" результат дают серии `1`, `4`, `13`, `40`, `121` или `1`, `3`, `7`, `15`, `31`, ... При этом сложность метода при хорошем распределении серии пропорционально $O(n^{1.2})$.

- Отдельно группируются и сортируются элементы стоящие друг от друга на расстоянии $n/2$. Затем на расстоянии $n/4$ и так далее, пока не дойдём до обычной одинарной сортировки.
- На каждом проходе сортировка программируется как сортировка вставками, поэтому если какая-то последовательность уже отсортирована, происходит переход к следующей.

Сортировка массива:

- 10, 4, 55, 66, 4, 123, 12, 666
- <span style="color:red">4</span>, <span style="color:aqua">4</span>, <span style="color:orange">12</span>, <span style="color:lime">66</span>, <span style="color:red">10</span>, <span style="color:aqua">123</span>, <span style="color:orange">55</span>, <span style="color:lime">666</span>
- <span style="color:red">4</span>, <span style="color:lime">4</span>, <span style="color:red">10</span>, <span style="color:lime">66</span>, <span style="color:red">12</span>, <span style="color:lime">123</span>, <span style="color:red">55</span>, <span style="color:lime">666</span>
- 4, 4, 10, 12, 55, 66, 123, 666

```cpp
void shell(int *arr, int n) {
	int step = n / 2;
	while (step > 0) {
		for (int i = 0; i < (n - step); i++) {
			int j = i;
			while (j >= 0 && m[j] > m[j + step]) {
				swap(m[j], m[j + step]);
				j -= step;
			}
		}
		step /= 2;
	}
}
```

### Пирамидальная сортировка

- Одномерный массив представляется в виде бинарного дерева. Левый потомок - элемент 1, правый - 2.
- Все узлы дерева выстраиваются в таком порядке, что никакой родитель не меньше своих прямых потомков.
- В результате такой процедуры в корне дерева (0й элемент массива) появляется наибольший элемент. Поменяем его местами с последним.
- Все элементы дерева находятся на своих местах за исключением нулевого элемента. Его нужно "протолкнуть" по дереву до требуемого места.
- После этого в корне дерева вновь оказывается максимальный элемент из оставшихся. Поменяем его местами с предпоследним.
- Повторяем алгоритм до тех пор пока первый элемент не сдвинуть.

```
Массив: [10 4 66 66 4 123 12 666]
Дерево:
         10
     4        55
   66  4   123   12
666
```

Выстраивание дерева в "хорошем" виде требует одноразового прохода по всем элементам: сложность подготовки - $O(n)$. В дальнейшем каждый элемент проталкиваем по дереву, затрачивая на это не более $log_2(n)$ и сложность $O(nlog_2(n))$.
 
Итоговая сложность: $O(n \times log_2(n))$ всегда.

```cpp
void push_down(int *arr, int root, int bottom) {
	bool done = false;
	int max_child;
	while ((root*2 + 1) <= bottom && !done) {
		if ((root*2 + 1) == bottom)
			max_child = root*2 + 1;
		else
			if (arr[root*2 + 1] > m[root*2 + 2])
				max_child = root*2 + 1;
			else
				max_child = root*2 + 2;

		if (arr[root] < arr[max_child]) {
			swap(arr[root], arr[max_child]);
			root = max_child;
		} else done = true;
}

void heap_sort(int *arr, int n) {
	for (int i = n/2 - 1; i >= 0; i--)
		pushDown(arr, i, n - 1);

	for (int i = n - 1; i >= 0; i--) {
		swap(arr[0], arr[i])
		pushDown(arr, 0, i - 1);
	}
}
```

### Быстрая сортировка

В массиве выбирается так называемый опорный элемент, стоящий в его центре.

После этого все элементы массива переставляются таким образом, что слева оказываются элементы, а справа - больше, либо равные.

Далее, данное правило применяется к левой и правой частям массива.

Обмен элементами производится следующим образом:
- Слева ищется элемент не меньше опорного
- Справа - не больший
- Меняются местами

И так далее


Если ключевой элемент выбирается таким образом, что все элементы массива делятся им по значениям ровно пополам, то левая и правая части относительно ключа будут одинаковы и количество таких делений.

При этом на каждом проходе пробегаем по всем элементам. Сложность: $O(n* \log{n})$.

Но в худшем случае, если ключом оказывается минимальный или максимальный элемент, то только он окажется на своём месте, а остальные элементы - либо справа, либо слева от него. Сложность: $O(n^2)$.

```cpp
void sort (int *arr, int left, int right) {
	int i = left, j = right, key = arr[(left + right) / 2];
	do {
		while (arr[i] < key) i++;
		while (arr[j] > key) j--;
		if (i <= j) {
			swap(arr[i], arr[j]);
			i++;
			j--;
		}
	} while (i <= j);
	if (i < right) sort(arr, i, right);
	if (j > left) sort(arr, left, j);
}

void quickSort(int *arr, int n) {
	sort(arr, 0, n - 1);
}
```

### Карманная сортировка

Это единственная сортировка, которая может упорядочить элементы за время $O(n)$, но для этого множество всех возможных значений ключа должно быть ограничено и мы это ограничение должны знать.

Для сортировки заводится массив "карманов". Каждый элемент массива (карман) - указатель на список, в котором расположены объекты с ключом, совпадающим с индексом "кармана".


## Внешняя сортировка

Файлы устроены таким образом, что в каждый момент времени доступна только одна компонента файла. Поэтому для данных, находящихся в файле, стандартные методы сортировки не подходят.

В отличие от оперативной памяти, размер внешней существенно больше и при сортировке можно использовать дополнительные контейнеры. На этом и основаны большинство подходов внешней сортировки.

### Прямое слияние

Алгоритм:

1. Последовательность $a$ разбивается на две половины $b$ и $c$.
2. Половины $b$ и $c$ сливаются в одну последовательность, при этом одиночные элементы из двух частей образуют упорядоченную пару.
3. Полученная последовательность под именем $a$ вновь делится пополам на $b$ и $c$ и далее выполняется пункт 2, но упорядоченные пары из каждой части уже сливаются в упорядоченные четвёрки.
4. Далее вновь разделение и четвёрки сливаются в восьмёрки и т.д. так до тех пор, пока не получится упорядоченная последовательность $a$.

Действие по однократной обработке всех элементов последовательности называется **фазой**.

Наименьший процесс повторение которого составляет сортировку называется **проходом**.

В примере лекции сортировка балы произведена за 3 прохода, каждая из которых состоит из фазы разделения и фазы слияния.

Поскольку на каждом проходе размер сливаемых групп увеличивается в 2 раза, то таких проходов $\log_2(n)$. При этом каждый раз проходятся все $n$ элементов дважды, а значит сложность - $O(n\log_2(n))$.

#### Усовершенствование

Можно заметить, что фаза разделения к самому процессу сортировки (сравнения элементов) отношения не имеет, поэтому сортировку можно усовершенствовать, сливая группы не в один файл $a$, а в два - по очереди.

Эти два вновь полученных файла и будут исходными для вновь сливаемых последовательностей.

## Естественное слияние

В случае прямого слияния мы не получаем никакого преимущества, даже если последовательность уже частично или полностью отсортирована.

На самом деле можно делить файлы на последовательности разной длины, если эти последовательности уже отсортированы естественным образом. В этом случае сразу сливаются не одиночные элементы, а наибольшие по длине отсортированные последовательности.

## Многопутевое слияние

Очевидно, что количество проходов можно уменьшить, если увеличить число файлов, на которые будем делить исходный - на $k$ файлов. Тогда сложность $\log_k(n)$.

## Многофазное слияние

В основе метода лежит идея отказа от понятия прохода.

Пусть у нас имеются два файла, в первом из которых $n1$ естественных серий, а во втором - $n2$, причём $n1 > n2$.

Будем сливать серии в третий файл, пока во втором они не закончатся.

Теперь, станем сливать первый и третий во второй и т.д.

Нетрудно заметить, что количество строк в таблице, а значит и количество действий по слиянию сильно зависит от количества серий в двух исходных файлах $F_1$ и $F_2$.

Лучший результат получается, когда исходные количества серий в файлах $F_1$ и $F_2$ являются соседними числами Фибоначчи.# Сложность алгоритмов

Скорость выполнения некоторой программы во многом зависит от быстродействия компьютера, но даже на самом быстром компьютере одни программы будут работать быстро, а другие - либо медленно, либо вообще не выдавать результат за разумное время.

Это связано не с производительностью техники, а со **сложностью алгоритма**. Под сложностью понимается количество элементарных операций (очень часто - шагов цикла), которые будут выполнены с исходными данными размером $n$.

Например, если для решения задачи используется два цикла, один из которых вложен в другой, и каждый цикл производит $n$ итераций, а тело цикла выполняется всегда выполняется за некоторое константное время $c$, то время на выполнение будет пропорционально $c \times n^2$.

При малых $n$ константа $c$ играет существенное значение, но чем больше $n$, тем значение $c$ уменьшается. Поэтому при оценке сложности все подобные константы не учитываются.

Сложность чаще всего (но не всегда) оценивается сверху (хуже чего не будет). И это описывается так называемой $O$-символикой: $O(f(n))$.

В конкретном данном примере сложность записывается: $O(n^2)$.
# Задача поиска

Имеется последовательность объектов (записей), требуется отыскать объект по некоторому значению ключа, либо сказать что объект отсутствует.

## Последовательный поиск

Все элементы последовательности просматриваются один за другим, пока искомый не будет найден или не будет просмотрена вся последовательность.

Сложность: $O(n)$.

```cpp
int straightSearch(int *arr, int n, int key) {
	int i = 0;
	while (i < n && arr[i] != key) i++;
	if (i < n) return i;
	return -1;
}
```

В цикле while первое условие к поиску элемента никакого отношения не имеет. Чтобы его избежать опишем массив на один элемент больше, чем его реальный размер и при поиске на последнее $n$-е место в массиве будем ставить искомый ключ. Этот ключ будет выступать как барьер.

## Бинарный поиск

Данный поиск проводится на **отсортированной последовательности** так называемым методом половинного деления.

Алгоритм:

- Находим элемент, находящийся в середине массива (с индексом $n/2$) и сравниваем искомый ключ с данным элементом.
- Если ключ равен искомому - поиск закончен. Если меньше среднего - поиск продолжаем в левой половине, если больше - в правой.

Сложность алгоритма: $O(\log_2(n))$

```cpp
int binarySearch(int *arr, int n, int key) {
	int left = 0, right = n - 1;
	int i = (left + right) / 2;
	while (left <= right && key != arr[i]) {
		if (key < arr[i]) right = i - 1;
		if (key > arr[i]) left = i + 1;
		i = (left + right) / 2;
	}
	if (left <= right) return i;
	return -1;
}
```


## Дерево поиска

Алгоритм:

- Первый элемент последовательности становится корнем **бинарного** дерева.
- Каждый следующий добавляется по правилу: 
	- Если элемент меньше корня - налево.
	- Если элемент больше корня - направо.

```
8, 4, 55, 66, 4, 123, 12, 666

      8
  44      55
4       12  66
               123
                  666
```

Поиск по такому дереву происходит пойдёт сравнением искомого ключа со значением в узле и дальнейшим проходом налево, либо направо в зависимости от того, меньше искомый ключ значения в узле или больше.

**При симметричном обходе дерева, выводится отсортированная последовательность значений.**

Если дерево поиска получилось сбалансированное, то сложность поиска по нему: $O(\log_2(n))$.

В худшем случае дерево может выродиться в линейный список и сложность будет $O(n)$.

```cpp
struct node {
	string word;
	int count;
	node *left, *right;
};

void insert(node *root, string word) {
	if (root == NULL) {
		root = new node;
		root->word = word;
		root->count = 1;
		root->left = NULL;
		root->right = NULL;
	}
	else if (word < root->word)
		insert(root->left, word);
	else if (word > root->word)
		insert(root->right, word);
	else
		root->count++;
}
```

## АВЛ-деревья

Чтобы дерево поиска не выродилось в линейный список, хорошо бы было его поддерживать в сбалансированном виде. Красивое решение было предложено в 1962 году советскими математиками Адельсом-Вельским и Ландисом.

Их метод требует всего двух дополнительных битов на узел для поддержания дерева поиска в сбалансированном состоянии всегда.

> Изобразим пример сбалансированного дерева, на котором для каждого узла отметим фактор сбалансированности в зависимости от разности высот правого и левого поддеревьев узла.
> 
> Это сбалансированное дерево имеет высоту 4, а также 8 листьев.
> 
> Дерево останется сбалансированным, если добавить ещё один узел после узлов 2, 5, 6. В остальных случаях потребуется дополнительная корректировка.

Проблема возникает в двух случаях:

1. Одна из сторон становится больше с той же стороны. Модификатор становится не +1 или -1, а +2 или -2, что значит одна из сторон имеет вес больше.  
   Случай, например, когда у ноды справа появляется ещё одна нода справа.
   Решением является перемещение текущей ноды выше на один уровень.
2. Одна из сторон становится больше с другой стороны.
   Случай, например, когда у ноды справа появляется нода слева.
   Тогда для решения нужно создать новую ноду, корневую ноду поддерева отправить налево, а её зависимую - направо. К . ноде поддерева крепится требуемая.

Два других "неприятных" случая могут быть получены из указанных при зеркальном отражении относительно вертикальной оси.

Стоит заметить, что новые деревья имеют ту же высоту что и до вставки элемента. Это значит, что всё дерево поиска, находящееся выше корневого узла разбалансировки остаётся в прежнем сбалансированном виде.

## Красно-чёрные деревья

**Красно-чёрные деревья** - бинарные деревья поиска, у которых для каждой вершины добавляется дополнительное свойство: вершина является чёрной или красной.

Требуется выполнение свойств:

- Корень дерева - чёрный
- У каждой красной вершины потомки - чёрные
- В двух любых ветвях от корня до листа количество содержащихся чёрных вершин равно

![Pasted image 20240402162407.png](../../Pasted%20image%2020240402162407.png#)

Чтобы всегда выполнялось третье условие красно-чёрного дерева, при реализации считается, что все листья дерева - чёрные.

Математически подсчитано, что в дереве, содержащем $N$ узлов, $\log_2{N} < h <= 2\log_2{(N+1)}$

Структура для КЧД выглядит просто:

```cpp
struct RBTree {
	bool color;
	int key;
	RBTree *parent;
	RBTree *left, *right;
}
```

Вставка элемента:
1. Случай 1. Дядя вершины x - красный.  
   Перекрашиваем родителя, дядю и деда, а затем проверяем выше, если бы x был дедом.
2. Случай 2. Дядя вершины x - чёрный, x и родитель - левые потомки.
   Брат x становится на место родителя x, а родитель x становится родителем деда. Родитель x становится чёрным, а дед становится красным.
3. Случай 3. Дядя вершины x - чёрный, но x - правый потомок, а родитель - левый потомок.
   x сохраняет своего правого потомка, а левым потомком становится его родитель.

## B-деревья

В каждой вершине B-деревьев может содержаться несколько ключей. Высота дерева определяется как максимальное количество вершин в ветви.

Будем рассматривать случай, когда все ключи различны. B-дерево степени $n$ определяется следующим образом:

1. Каждая вершина, кроме корня, содержит от $n-1$ до $2n - 1$ ключей и от $n$ до $2n$ ссылок на узлы-потомки. Корень дерева содержит не более $2n-1$ ключей и $2n$ ссылок.
2. B-дерево идеально сбалансировано и длина каждой ветви одинакова.
3. Элементы в каждой вершине упорядочены по возрастанию.
4. Если в вершине находится $k$ элементов, то в ней $k+1$ ссылка на потомков.
5. Элементы в вершине и ссылки сопоставляются так:
	- Про первую ссылку говорят, что она находится до первого элемента.
	- Последняя - после последнего.
	- Все остальные - между парами элементов.
6. Если узел является потомком от узла с ссылкой, пришедшей от пары $(a, b)$, то все значения в узле больше $a$, меньше $b$.

Высота B-дерева $h \leq \log_n{(N+1)}/2 + 1$, где $n$ - степень дерева, $N$ - количество элементов (ключей).

Поиск по такому дереву происходит, как в обычном дереве поиска, но в каждом узле необходимо найти соответствующую ссылку.


## Хэширование

Данный метод требует фиксированного, обычно малого, времени на выполнение операции поиска.

Выделяют два вида хеширования:

- Открытое, внешнее или расширенное
- Закрытое, внутреннее или прямое

Термин "хэширование" произошёл от глагола "to hash" - рубить, измельчать, перемешивать.

Всё множество значений ключа разбивается на $B$ классов, пронумерованных от $0$ до $B-1$.

Далее строится хэш-функция $h$, что для любого элемента $x$ из исходного множества ключей, функция $h(x)$ принимает целочисленное значение из отрезка от $0$ до $B-1$. Это значение и есть номер класса, в который помещается элемент $x$.

### Открытое хэширование

$B$ указателей, каждый из которых хранит адрес списка элементов с одним и тем же хэшем, равным индексу ячейки.

Ситуация, когда два элемента имеют один и тот же хэш называется коллизией. Размер таблицы $B$ и вид хэш-функции $h$ обычно выбираются такими, чтобы количество коллизий сводилось к минимуму.

> В Java для ячеек с большим количеством коллизий вектор превращается в красно-чёрное дерево


#### Пример

Ключи: `13, 19, 3, 52, 59, 14, 64, 69, 34`

$B = 5$  $h(x) = x\ \%\ B$

![Pasted image 20240409161843.png](../../Pasted%20image%2020240409161843.png#)

Поиск по такой таблице происходит вычислением значения $h(x)$ и прохождением по списку сегмента $x$. 

Самые большие проблемы происходят в 4м сегменте из-за большого количества коллизий.

> Для лабораторной:  
> $h(x) = (a\times x+c)\ \%\ B$

### Закрытое хэширование

При закрытом хэшировании в таблице сегментов хранятся сами элементы, а не указатели. Поэтому в каждом сегменте может находиться лишь один элемент, а это значит, что в закрытой хэш-таблице не может быть размещено более $B$ элементов, где $B$ - размер таблицы.

Кроме того, возникают проблемы в случае коллизии. На помощью приходят дополнительные хэш-функции. Если на функции $h_0(x)$ произошла коллизия, к объекту применяются функции $h_1(x)$, $h_2(x)$ и так далее, пока не будет найдена свободная ячейка.

Вид функции для повторного кэширования может быть например такой: $h_i(x) = (h_0(x)+i)\ \%\ B$.

При закрытом хэшировании возникает ещё одно проблема - удаление элемента. Сегмент, из которого удалён элемент с одной стороны должен быть пустым, чтобы в него можно было поместить новый, а с другой - не совсем пустым, чтобы не потерять элементы с тем же хэшем, расположенные из-за коллизии после удалённой ячейки.

Поэтому в закрытой хэш-таблице помимо хэшей приходится держать ещё два значения:

- Пустая ячейка - в неё производится новая запись и до неё поиск элементов.
- Удалённая ячейка - в неё также возможна запись, но поиск элементов в случае коллизии продолжается дальше.

Формула $h_i(x) = (h_0(x)+i)\ \%\ B$ является не очень хорошей с точки зрения разрешения коллизий, поэтому рекомендуют использовать другие варианты:

- $h_i(x) = (h_0(x)+C_i)\ \%\ B$, где на каждом $i$-м шаге $C_i$ - новая константа, взаимно простая с $B$.
- $h_i(x) = (h_0(x)+d_i)\ \%\ B$, где $d_1$, $d_2$, $d_3$, ..., $d_{B-1}$ - некоторая перестановка чисел: $1$, $2$, $3$, ..., $B-1$.0# Классы сложности задач

В 60-е годы XX века встал вопрос: А все ли задачи *теоретически* имеют алгоритм для своего решения, который выполняется за "разумное" время?

Для ответа на этот вопрос были введены сложностные классы задач (классы сложности).

## 1. Класс $P$

К этому классу относятся все задачи, которые можно решить за полиномиальное время. То есть сложность алгоритма, решающего эту задачу - $O(n^k)$, где $n$ - длина входных данных, $k$ - некое целое число, большее нуля.

Полиномы хороши ещё тем, что обладают тем свойством, что их сумма и произведение - также полином.

Считается, что все задачи, имеющие для своего решения полиномиальные алгоритмы, решаются за "разумное" время.

## 2. Класс $NP$ - полиноминально проверяемые задачи

Пусть имеется некоторое решение задачи. Если за полиномиальное время можно проверить верно это решение или нет, то задача относится к классу $NP$.

Очевидно, что все полиномиальные задачи - задачи класса $P$ - одновременно относятся и к классу $NP$.

Обратное утверждение (все $NP$ - $P$) до сих пор стоит под вопросом.

Пример задачи, которая относится к классу $NP$, но для которой до сих пор не известен полиномиальный алгоритм решения:

Дано множество чисел $a_1$, $a_2$, ... $a_n$ и число $B$. Найти такой вектор $X = (x_1, x_2, ..., x_n)$, где $x_i \in \{0, 1\}$, где $(x_1 \times a_1) + (x_2 \times a_2) +\ ...\ + (x_n \times a_n) = B$.

## 3. Класс $NPC$ - $NP$-полные задачи

> $NP$-Complete.

Понятие $NPC$ задач было введено в начале 70-х годов XX века и напрямую связано с понятием сводимости одной задачи к другой.

Под сводимостью понимается следующее:  
Пусть имеется задача $Z_1$ и правильно решающий её алгоритм $A_1$ и задача $Z_2$, алгоритм решения которой неизвестен. Если мы сможем переформулировать $Z_2$ в терминах $Z_1$, то будет возможность её решения тем же алгоритмом $A_1$.

К классу $NPC$ относятся те задачи, к которым могут быть сведены все $NP$.

Любую $NP$ задачу можно привести к $NPC$.

Если в классе $NPC$ найдётся хоть одна задача, для которой будет найден полиномиальный алгоритм.

## Кружочки

![Pasted image 20240416163930.png](../../Pasted%20image%2020240416163930.png#)# Алгоритмы криптографии

**Криптография** - наука о методах обеспечения конфиденциальности и аутентичности информации.

**Криптоанализ** - наука о методах расшифровки зашифрованной информации без предназначенного для расшифровки ключа.

**Ключ** - секретный блок данных, используемый криптографическим алгоритмом при шифровании, дешифровании, постановке и проверке цифровой подписи, вычислении кода, аутентификации.

#### Древние способы шифрования

Самые простые и слабые:

- Шифр Цезаря
- Квадрат Полибия

Решётка Кардано - Достаточно мощный способ шифрования с ключом

Таблица Вижинера - Первый способ шифрования с текстовым ключом.

Шифр Вернама - появился в начале XX века, когда появился телеграм.

## Классификация криптоалгоритмов

### По способу шифрования

- **Тайнопись**  
	Скрывается сам алгоритм, по которому прячутся данные  
	Если злоумышленник узнает алгоритм - информация будет раскрыта  
	*Большинство учёных на сегодняшний день тайнопись к криптографии не относят*
- **Шифрование с ключом**
	Текст, который подлежит шифрованию называется **открытым текстом**. Зашифрованный - **шифртекст**. Между открытым и шифртекстом находится алгоритм, результат работы которого зависит от **ключа шифрования**. На сегодняшний день надёжным считается ключ 256 бит и более.

### По способу использования ключа

- **Симметричные криптоалгоритмы**  
	Для шифрования и дешифрования используется один и тот же ключ.
- **Ассиметричные криптоалгоритмы**  
	Шифрование производится открытым ключом, известным всем желающим. Дешифрование - закрытым ключом, известным только получателю.

### По воздействию на шифруемые данные

- **Перестановочные алгоритмы**  
	Алгоритм лишь переставляет биты исходного текста по некоторому правилу.
- **Подстановочные алгоритмы**  
	Сам блок, подлежащий шифрованию меняется по законам криптоалгоритма.

### По размеру шифруемого блока

- **Поточные криптоалгоритмы**  
	Отдельно шифруется каждый бит исходного текста
- **Блочные криптоалгоритмы**  
	Шифруется разу целый блок бит (16, 32, 64, 128, ...)  
	Результаты шифрования зависят от всех бит шифруемого блока

Наиболее надёжные на сегодняшний день шифры - симметричные подстановочные блочные.# Шифры

## Шифры гаммирования

Пример: Шифр Вернама

Плюсы:

- Простота шифрования
- Невозможность расшифровать открытый текст не зная гаммы, если длина гаммы >= длины открытого текста

Минусы:

- Если злоумышленнику известна часть открытого текста и соответствующий зашифрованный - находится часть гаммы.

## Симметричные блочные шифры

Для обозначения мы будем использовать *специальные обозначения, которые мне перерисовывать и фоткать лень*.

Во всех формулах под параметром $V$ обычно понимают:

1. Некоторую константу
2. Часть шифруемого блока
3. Материал ключа

S-box - табличная подстановка. Одна из биективных математических функций шифрации.

Создаём табличку из 16 ячеек. Заполняем случайными 4битными числами. Берём каждый 4битный блок кода и используем его число как id для поиска в таблице новой замены.

### Сеть Фейштеля

![Pasted image 20240507153827.png](../../Pasted%20image%2020240507153827.png#)

Сеть Фейштеля является классической схемой симметричного шифрования. 

Исходный блок делится на две части $x_1$ и $x_2$. К части $x_1$ применяется образующая функция $f$, результат с помощью операции $XOR$ накладывается на часть $x_2$ и ветви меняются местами. Подобное действие называется раундом сети. Обычно количество раундов 8-32. В конце алгоритма ветви просто меняются местами.

Параметры $V_1, V_2, ..., V_r$ обычно являются материалами ключа.

Криптостойкость схемы нелинейно возрастает с увеличением числа раундов.

Размер блока как правило от 64 до 256 бит.

Поскольку наложение одной ветви на другую производится с помощью операции XOR, а она обратима при повторном использовании, то ту же самую сеть можно использовать для дешифрования, лишь изменив порядок параметров $V_i$ на обратный.

#### Пример на C++

```cpp
int f(int x1, int v) { return x1 + v; }

struct OutData { int x1, x2; };
OutData encrypt(int x1, int x2, int *key, int r) {
	for (int i = 0; i < r; i++) {
		x2 = x2 ^ f(x1, key[i]);
		swap(x1, x2);
	}
	swap(x1, x2);
	return { x1, x2 };
}

OutData decrypt(int x1, int x2, int *key, int r) {
	for (int i = r-1; i >= 0; i--) {
		x2 = x2 ^ f(x1, key[i]);
		swap(x1, x2);
	}
	swap(x1, x2);
	return { x1, x2 };
}

int main() {
	int x1 = 2000000000, x2 = 1;
	int key[8] = { 1, 2, 3, 4, 5, 6, 7, 8 };

	OutData enc = encrypt(x1, x2, key, 8);
	OutData dec = decrypt(enc.x1, enc.x2, key, 8);
	cout << "In: " << x1 << " " << x2 << endl;
	cout << "Enc: " << enc.x1 << " " << enc.x2 << endl;
	cout << "Dec: " << dec.x1 << " " << dec.x2 << endl;

	return 0;
}
```


## Алгоритм DES - Data Encryption Standart

В 1977 году был предложен, а в 1980 году принят как стандарт симметричного шифрования США алгоритм DES.

Сам алгоритм представляет классическую сеть Фейштеля из 16 раундов с единственным добавлением так называемого начального и конечного "забеливания" - перемешивания бит исходного блока перед началом работы сети и конечного блока после работы сети. Размер шифруемого блока: 64 бита. Размер ключа: 56 бит. Образующая функция:

1. Поступают 32 бита
2. Расширяются до 48 бит
3. К ним прибавляется с помощью операции $XOR$ материал ключа.
4. 48 бит делятся на группы по 6 бит.
5. Каждая из них используется в S-box'е с выходом 4 бита.
6. На выходе 32 бита.


![Pasted image 20240507162330.png](../../Pasted%20image%2020240507162330.png#)

## Алгоритм 3DES

$DES(k_3, DES(k_2, DES(k_1, M)))$

Сообщение $M$ шифруется через $DES$ сначала ключом $k_1$, затем - $k_2$, и после - $k_3$.

Самая популярная разновидность 3DES - это DES-EDE3 - 3 ключа, первый шифрует, второй расшифровывает, третий вновь шифрует.


## ГОСТ 28147-89

Ключ: 256 бит. Раунды: 32.

Образующая функция:

![Pasted image 20240507163458.png](../../Pasted%20image%2020240507163458.png#)


## Ассиметричная криптография

Ассиметричная криптография даёт также симпатичное решение цифровой подписи документов.

Цифровая подпись - это некоторый идентификатор, который подтверждает целостность пришедшего документа, а также его авторство.

Будем находить от открытого текста хэш-значение - число, имеющее определённый размер, и уникально определяющее открытый текст. При этом это значение должно отвечать как минимум двум требованиям:

- Размер хэша в битах для любого текста должен быть один и тот же
- При изменении текста на 1 бит идеальный хэш инвертирует половину произвольных бит.

Стандартный размер хэша: 64, 128, 256 бит

Теоретически можно подобрать текст с тем же самым хэшем, что и у шифруемого текста, но это придётся делать полным перебором и полученный текст вряд ли будет осмысленным.

# Генерация случайных чисел

Генераторы случайных чисел:

- Автоматические
- Автоматизированные

Генераторы псевдо-случайных чисел:

- Общего назначения
- Криптогенераторы

